 \documentclass[a4paper]{article}
%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[letterpaper, portrait, margin=1in,top=1in,bottom=1.5in]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage[shortlabels]{enumitem}
\newenvironment{exercise}[1]{\textbf{#1.}}

\begin{document}

\begin{flushright}
Cory Glover\\
1/25/20\\
Math 525
\end{flushright}

\begin{exercise}{1}
C
\end{exercise}

\begin{exercise}{2}
B
\end{exercise}

\begin{exercise}{3}
\begin{enumerate}
\item 7.3
\begin{enumerate}
\item Consider Katz centrality $\mathbf{x}=\alpha A\mathbf{x}+\mathbf{1}$. Solving we get $(I-\alpha A)\mathbf{x}=\mathbf{1}$. If we can take an inverse (which we can with probability 1), we get that $\mathbf{x}=(I-\alpha A)^{-1}\mathbf{1}$. We then see we have a geometric series. So
\begin{align}
\mathbf{x}&=\Bigl(\sum_{i=0}^\infty (\alpha A)^r\Bigr)\mathbf{1}\\
&=\mathbf{1}+\alpha A\mathbf{1}+\alpha^2A^2\mathbf{1}+\dotsb.
\end{align}

\item Recall that $A\mathbf{1}=\mathbf{k}$. So we have that $\mathbf{x}=\mathbf{1}+\alpha\mathbf{k}+\alpha^2 A\mathbf{k}+\dotsb$. Thus, we get that $\mathbf{x}=\mathbf{1}+(\sum_{i=0}^\infty\alpha^{i+1} A^{i})\mathbf{k}=\mathbf{1}+\alpha(\sum_{i=0}^\infty\alpha^i A^i)\mathbf{k}$. Thus, for small $\alpha$, we get that $\mathbf{x}\approx\mathbf{1}+\alpha\mathbf{k}$ since the terms $\alpha^r\mathbf{k}$ for $r\geq 2$ go to zero much faster. Adding $\mathbf{1}$ to $\mathbf{k}$ does not change the ranking of $\mathbf{k}$ and multiplying each entry of $\mathbf{k}$ by the same constant $\alpha$ does not change the ranking. So $\mathbf{x}$ gives the same ranking at $\mathbf{k}$ (i.e. degree centrality) as $\alpha\rightarrow 0$.

\item Consider when $\alpha\rightarrow\frac{1}{\kappa_1}$. Then by part (a) we have that $\mathbf{x}$ is approaching
\[\mathbf{x}\rightarrow\frac{1}{\kappa_1}A\mathbf{x}+\mathbf{1}.\]
Note that adding 1 to each entry of $\frac{1}{\kappa_1}A\mathbf{x}$ does not change the ranking of any of the nodes. Thus the ranking of $\frac{1}{\kappa_1}A\mathbf{x}+\mathbf{1}$ is the same as eigenvector centrality. Thus, $\mathbf{x}$ approaches eigenvector centrality as $\alpha\rightarrow\frac{1}{\kappa_1}$.
\end{enumerate}

\item 7.5: Let the center node be defined as $x_1$. Then 
\[x_1=\alpha\sum_{j}A_{1j}\frac{x_j}{k_j^{out}}+\beta.\]
Since we are looking at a tree, we know that $k_j^{out}=1$ for all nodes $x_j$. So we get that
\[x_1=\alpha\sum_jA_{1j}x_j+\beta.\]
This is just Katz centrality. Thus by problem 7.3, we see that
\[x_1=\beta(1+\alpha\sum_jA_{1j}\mathbf{1}+\alpha^2\sum_jA_{1j}^2\mathbf{1}+\dotsb).\]
Recall that $\sum_jA_{1j}^r\mathbf{1}$ counts the number of walks of length $r$ to 1. Since $G$ is a tree, we know that the number of walks of length $r$ to 1 is the number of nodes with $d_i=r$ (where $d_i$ is the distance from $i$ to the center node). This means that $x_1=\beta(1+\sum_{i}\alpha^{d_i})$.
\end{enumerate}
\end{exercise}
\end{document}